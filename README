Final project for Intermediate Programming 600.120 (1) in Fall 2016.

Lionel Eisenberg (leisenb5)
Sanat Deshpande (sdeshpa4)
-----------------------------------------------------------------------

Contents:
1. /data

	empty_list.txt: test case for empty file list
	master_vector_test.txt: contains a list of 4 text files
	/test_doc_set: contains text files for testing purposes
		test1.txt
		test2.txt
		test3.txt
		test4.txt
		file1.txt
		file2.txt
		file3.txt
		getContentTest.txt
	test_file_list.txt: contains only some test filenames
	test2_file_list.txt: contains only some test filenames

2. /include

	catch.hpp: unit testing framework
	CheckPlagiarism.hpp: header file for class containing methods to compare two files for plagiarism
	Managing.hpp: header file for class that sifts through files and compares pairs
3. /src

	CheckPlagiarism.cpp: Contains method definitions for functions to check the content of two files for plagiarism
   	Makefile: This compiles the project into the executable <finalProject>
   	unitTest-PlagiarismCheck.cpp: Contains unit tests
   	driver.cpp: creates a "Managing" object and passes all user input into it
   	Managing.cpp: receives user input and systematically compares files for plagiarism using CheckPlagiarism.cpp
   	unitTestDriver.cpp: driver for unit tests

4. gitlog.txt

------------------------------------------------------------------------

What our code does, and how to run it:

Running the command "make" will yield an executable called "finalProject".
Our program takes two command line arguments:
    1. filePath of text file containing list of test documents
    2. 'l', 'm', or 'h' (low, medium, or high rigor in testing for plagiarism, high rigor returning the most suspicious files, low rigor returning the least).
If the second argument is not included, then it is assumed to be 'm'

Example:
	./finalProject ~cs120/public_data/sm_doc_list.txt h
This means that the files listed in sm_doc_list.txt will be compared against each other with a high rigor for plagiarism.
The output will be a list of file pairs that our program deems suspicious. This will be printed to screen. Additionally,
each file pair will be printed to the screen as it is being evaluated. The aforementioned suspicious pairs will be printed in one
large list at the very end of the program. 

************************************
HOW IT WORKS:
    Functions that check for plagiarism:
    	- isSameFile:
		The isSamefile function takes the begin and end iterators of two vectors that represent the text of two files and checks, word for word if both functions are exactly the same. This helps us eliminate some files rather quickly by looking at their length. Moreover in a more fully fleshed out version of this project, we could have flags that indicate the degree to which two files are suspicious, in which case this function would be even more helpfull.
	- checNGram:
		The CheckNgram Function takes the begin and end iterators of two vectors that represent the text of two files. It then starts a nested for loop that will first look at the first word in the first file and look if there exist any matches in the second file, if there are then the function will compare the word after the match in the first file and the word after the match in the second file. If there are more than three mismatches then the function will stop, tabulate the length of the mismatched sentence and then start again except the iterator for the first file will be reset to the last matched word. (for further explanation see comments).
	- CheckControlC:
	  	The CheckControlC function works very similarily to the checkNgram function, except it tabulates the levenshtein distance between words which basically counts the number of substitutions, deletions or additions one would have to do to go from one word to another. it then looks at the average distance per word, and if the average distance goes over a certain threshhold then the sentences will no longer be the same.


************************************
TESTING:
To run testing, just make and run ./unitTest. Our unit tests just verify that our individual functions work, it is by no mean absolutely extensive.

***********************************
OPTIMISATION:
We commented out one of our methods when checking plagiarism that used the Levenshtein Distance algorithm to calculate the average distance
between two sentences. This method looks at plagiarism in more depth as it compares two sentences more accurately then just looking at two sentences
and seeing if their words are the same.
Please feel free to uncomment the else statemenet in our CheckPlagiarism.cpp file and run the test again. This will run slower as we are doing more
complicated operations, however the suspicious files catcher will be more thorough.

APPROXIMATE RUNTIME:
Our program runs through the small data set rather quickly, and runs faster on the 'h' setting.

approximate runtime:
    sm_doc_set ~ 1second - 3seconds (depending on rigor)
    med_doc_set ~ 8seconds - 20seconds
    big_doc_set ~ 30minutes - 1hour

Obviously runtime increases as the data set size increases, but each file pair being inspected is printed to screen to show the progress of the code
for the grader's convenience.
--------------------------------------------------------------------------

PROJECT FEEDBACK:
This project was rather fun to write, we enjoyed having less restrictions which let us be creative and have to think more on our own.
It was interesting to have to keep optimisation in mind, however it did force us to change our code as one section of our code took way too much time
to write.
Total this project took 25 hours to write.